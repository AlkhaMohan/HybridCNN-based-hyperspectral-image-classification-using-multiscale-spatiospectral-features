{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "pip install spectral"
      ],
      "metadata": {
        "id": "x667-6NShVGX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IbUExb0Ng02F"
      },
      "outputs": [],
      "source": [
        "import keras\n",
        "from keras.layers import Conv2D, Conv3D, Flatten, Dense, Reshape, BatchNormalization\n",
        "from keras.layers import Dropout, Input,concatenate\n",
        "from keras.models import Model\n",
        "from keras.optimizers import Adam,SGD\n",
        "from keras.callbacks import ModelCheckpoint\n",
        "from keras.callbacks import EarlyStopping\n",
        "from tensorflow.python.keras.utils import np_utils\n",
        "from keras.callbacks import EarlyStopping\n",
        "from sklearn.decomposition import PCA\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import confusion_matrix, accuracy_score, classification_report, cohen_kappa_score\n",
        "\n",
        "from operator import truediv\n",
        "\n",
        "from plotly.offline import init_notebook_mode\n",
        "from sklearn import random_projection\n",
        "from sklearn.decomposition import KernelPCA\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import scipy.io as sio\n",
        "import os\n",
        "import spectral\n",
        "\n",
        "init_notebook_mode(connected=True)\n",
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FPwgDbWWg02J"
      },
      "outputs": [],
      "source": [
        "## GLOBAL VARIABLES\n",
        "test_ratio = 0.6"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bMfRf-Vcg02J"
      },
      "outputs": [],
      "source": [
        "## Inputing the dataset Indianpine_GRPKPCA.npy is the 15 band PCA result of actual Indianpines dataset\n",
        "## ground truth is Indianpines_gt.npy\n",
        "\n",
        "def loadData():\n",
        "    data = np.load(\"Indianpine_GRPKPCA.npy\")\n",
        "    labels = np.load(\"Indianpines_gt.npy\")\n",
        "    return data, labels"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4-sNgfZAg02K"
      },
      "outputs": [],
      "source": [
        "def splitTrainTestSet(X, y, testRatio, randomState=345):\n",
        "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=testRatio, random_state=randomState,\n",
        "                                                        stratify=y)\n",
        "    return X_train, X_test, y_train, y_test"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8QUb2n6Pg02K"
      },
      "outputs": [],
      "source": [
        "def padWithZeros(X, margin=2):\n",
        "    newX = np.zeros((X.shape[0] + 2 * margin, X.shape[1] + 2* margin, X.shape[2]))\n",
        "    x_offset = margin\n",
        "    y_offset = margin\n",
        "    newX[x_offset:X.shape[0] + x_offset, y_offset:X.shape[1] + y_offset, :] = X\n",
        "    return newX"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wN6Afpxpg02K"
      },
      "outputs": [],
      "source": [
        "def createImageCubes(X, y, windowSize=5, removeZeroLabels = True):\n",
        "    margin = int((windowSize - 1) / 2)\n",
        "    zeroPaddedX = padWithZeros(X, margin=margin)\n",
        "    # split patches\n",
        "    patchesData = np.zeros((X.shape[0] * X.shape[1], windowSize, windowSize, X.shape[2]))\n",
        "    patchesLabels = np.zeros((X.shape[0] * X.shape[1]))\n",
        "    patchIndex = 0\n",
        "    for r in range(margin, zeroPaddedX.shape[0] - margin):\n",
        "        for c in range(margin, zeroPaddedX.shape[1] - margin):\n",
        "            patch = zeroPaddedX[r - margin:r + margin + 1, c - margin:c + margin + 1]\n",
        "            patchesData[patchIndex, :, :, :] = patch\n",
        "            patchesLabels[patchIndex] = y[r-margin, c-margin]\n",
        "            patchIndex = patchIndex + 1\n",
        "    if removeZeroLabels:\n",
        "        patchesData = patchesData[patchesLabels>0,:,:,:]\n",
        "        patchesLabels = patchesLabels[patchesLabels>0]\n",
        "        patchesLabels -= 1\n",
        "    return patchesData, patchesLabels"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kxwIRZbWg02L"
      },
      "outputs": [],
      "source": [
        "X, y = loadData()\n",
        "X.shape, y.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NEvnavAYg02L"
      },
      "outputs": [],
      "source": [
        "K = X.shape[2]\n",
        "K = 15 ## matching PCA size\n",
        "X.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NBRGbXsOg02M"
      },
      "outputs": [],
      "source": [
        "X1, y1 = createImageCubes(X, y, windowSize=15)\n",
        "print(X1.shape, y1.shape)\n",
        "Xtrain1, Xtest1, ytrain1, ytest1 = splitTrainTestSet(X1, y1, test_ratio)\n",
        "print(Xtrain1.shape, Xtest1.shape, ytrain1.shape, ytest1.shape)\n",
        "Xtrain1, Xvalid1, ytrain1, yvalid1 = splitTrainTestSet(Xtrain1, ytrain1, 0.2)\n",
        "print(Xtrain1.shape, Xvalid1.shape, ytrain1.shape, yvalid1.shape)\n",
        "Xtrain1 = Xtrain1.reshape(-1,15,15,K,1)\n",
        "print(Xtrain1.shape)\n",
        "Xvalid1 = Xvalid1.reshape(-1,15,15,K,1)\n",
        "print(Xvalid1.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lSbOb6P8g02M"
      },
      "outputs": [],
      "source": [
        "X2, y2 = createImageCubes(X, y, windowSize=13)\n",
        "print(X2.shape, y2.shape)\n",
        "Xtrain2, Xtest2, ytrain2, ytest2 = splitTrainTestSet(X2, y2, test_ratio)\n",
        "print(Xtrain2.shape, Xtest2.shape, ytrain2.shape, ytest2.shape)\n",
        "Xtrain2, Xvalid2, ytrain2, yvalid2 = splitTrainTestSet(Xtrain2, ytrain2, 0.2)\n",
        "print(Xtrain2.shape, Xvalid2.shape, ytrain2.shape, yvalid2.shape)\n",
        "Xtrain2 = Xtrain2.reshape(-1,13,13, K,1)\n",
        "print(Xtrain2.shape)\n",
        "Xvalid2 = Xvalid2.reshape(-1,13,13, K,1)\n",
        "print(Xvalid2.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KomCBZC9g02M"
      },
      "outputs": [],
      "source": [
        "X3, y3 = createImageCubes(X, y, windowSize=11)\n",
        "print(X3.shape, y3.shape)\n",
        "Xtrain3, Xtest3, ytrain3, ytest3 = splitTrainTestSet(X3, y3, test_ratio)\n",
        "print(Xtrain3.shape, Xtest3.shape, ytrain3.shape, ytest3.shape)\n",
        "Xtrain3, Xvalid3, ytrain3, yvalid3 = splitTrainTestSet(Xtrain3, ytrain3, 0.2)\n",
        "print(Xtrain3.shape, Xvalid3.shape, ytrain3.shape, yvalid3.shape)\n",
        "Xtrain3 = Xtrain3.reshape(-1,11,11, K,1)\n",
        "print(Xtrain3.shape)\n",
        "Xvalid3 = Xvalid3.reshape(-1,11,11, K,1)\n",
        "print(Xvalid3.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xE7Cn5oWg02N"
      },
      "outputs": [],
      "source": [
        "X4, y4 = createImageCubes(X, y, windowSize=9)\n",
        "print(X4.shape, y4.shape)\n",
        "Xtrain4, Xtest4, ytrain4, ytest4 = splitTrainTestSet(X4, y4, test_ratio)\n",
        "print(Xtrain4.shape, Xtest4.shape, ytrain4.shape, ytest4.shape)\n",
        "Xtrain4, Xvalid4, ytrain4, yvalid4 = splitTrainTestSet(Xtrain4, ytrain4, 0.2)\n",
        "print(Xtrain4.shape, Xvalid4.shape, ytrain4.shape, yvalid4.shape)\n",
        "Xtrain4 = Xtrain4.reshape(-1,9,9, K)\n",
        "print(Xtrain4.shape)\n",
        "Xvalid4 = Xvalid4.reshape(-1,9,9, K)\n",
        "print(Xvalid4.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z8CODK36g02N"
      },
      "source": [
        "X5, y5 = createImageCubes(X, y, windowSize=13)\n",
        "print(X5.shape, y5.shape)\n",
        "Xtrain5, Xtest5, ytrain5, ytest5 = splitTrainTestSet(X5, y5, test_ratio)\n",
        "print(Xtrain5.shape, Xtest5.shape, ytrain5.shape, ytest5.shape)\n",
        "Xtrain5, Xvalid5, ytrain5, yvalid5 = splitTrainTestSet(Xtrain5, ytrain5, 0.4)\n",
        "print(Xtrain5.shape, Xvalid5.shape, ytrain5.shape, yvalid5.shape)\n",
        "Xtrain5 = Xtrain5.reshape(-1,13,13,K)\n",
        "print(Xtrain5.shape)\n",
        "Xvalid5 = Xvalid5.reshape(-1,13,13,K)\n",
        "print(Xvalid5.shape)\n",
        "ytrain5 = np_utils.to_categorical(ytrain5,num_classes=16)\n",
        "print(ytrain5.shape)\n",
        "yvalid5 = np_utils.to_categorical(yvalid5)\n",
        "print(yvalid5.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "p9tt0Hiwg02O"
      },
      "outputs": [],
      "source": [
        "inputA=Input((15,15,15,1))\n",
        "c11=Conv3D(filters=32, kernel_size=(3,3,7), activation='relu')(inputA)\n",
        "#c11=BatchNormalization()(c11)\n",
        "c12=Conv3D(filters=64, kernel_size=(3,3,5), activation='relu')(c11)\n",
        "#c12=BatchNormalization()(c12)\n",
        "c13=Conv3D(filters=128, kernel_size=(3,3,3), activation='relu')(c12)\n",
        "c13_shape = c13.shape\n",
        "f1=Reshape((c13_shape [1], c13_shape [2], c13_shape [3]*c13_shape[4]),name='op1')(c13)\n",
        "model_a = Model(inputs=inputA, outputs=f1)\n",
        "model_a.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WpKkIFCLg02O"
      },
      "outputs": [],
      "source": [
        "inputB=Input((13,13,15,1))\n",
        "c21=Conv3D(filters=32, kernel_size=(3,3,7), activation='relu')(inputB)\n",
        "#c21=BatchNormalization()(c21)\n",
        "c22=Conv3D(filters=64, kernel_size=(3,3,5), activation='relu')(c21)\n",
        "#c22=BatchNormalization()(c22)\n",
        "c23=Conv3D(filters=128, kernel_size=(1,1,3), activation='relu')(c22)\n",
        "c23_shape = c23.shape\n",
        "f2=Reshape((c23_shape [1], c23_shape [2], c23_shape [3]*c23_shape[4]),name='op2')(c23)\n",
        "model_b = Model(inputs=inputB, outputs=f2)\n",
        "model_b.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eMLdHTRZg02O"
      },
      "outputs": [],
      "source": [
        "inputC=Input((11,11,15,1))\n",
        "c31=Conv3D(filters=32, kernel_size=(3,3,7), activation='relu')(inputC)\n",
        "#c31=BatchNormalization()(c31)\n",
        "c32=Conv3D(filters=64, kernel_size=(1,1,5), activation='relu')(c31)\n",
        "#c32=BatchNormalization()(c32)\n",
        "c33=Conv3D(filters=128, kernel_size=(1,1,3), activation='relu')(c32)\n",
        "c33_shape = c33.shape\n",
        "f3=Reshape((c33_shape [1], c33_shape [2], c33_shape [3]*c33_shape[4]),name='op3')(c33)\n",
        "model_c = Model(inputs=inputC, outputs=f3)\n",
        "model_c.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZapcWeGjg02O"
      },
      "outputs": [],
      "source": [
        "ip_from_a = model_a.get_layer(\"op1\").output\n",
        "ip_from_b = model_b.get_layer(\"op2\").output\n",
        "ip_from_c = model_c.get_layer(\"op3\").output\n",
        "#ip_from_d = model_d.get_layer(\"op4\").output\n",
        "#Feature_ip= concatenate([ip_from_a,ip_from_b,ip_from_c,ip_from_d])\n",
        "#print(Feature_ip.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qEMpmMUBg02P"
      },
      "outputs": [],
      "source": [
        "inputE=Input((9,9,15))\n",
        "Feature_ip1= concatenate([ip_from_a,ip_from_b,ip_from_c,inputE])\n",
        "conv_layer1=Conv2D(filters=64, kernel_size=(5,5), activation='relu')(Feature_ip1)\n",
        "conv_layer2 = Conv2D(filters=128,kernel_size=(3,3), activation='relu')(conv_layer1)\n",
        "flatten_layer = Flatten()(conv_layer2)\n",
        "dense_layer1 = Dense(units=256, activation='relu')(flatten_layer)\n",
        "#dense_layer1=BatchNormalization()(dense_layer1)\n",
        "dense_layer1 = Dropout(0.2)(dense_layer1)\n",
        "dense_layer2 = Dense(units=128, activation='relu')(flatten_layer)\n",
        "#dense_layer2=BatchNormalization()(dense_layer2)\n",
        "dense_layer2 = Dropout(0.2)(dense_layer2)\n",
        "output_layer = Dense(units=16, activation='softmax')(dense_layer2)\n",
        "model_e = Model(inputs=[model_a.input,model_b.input,model_c.input,inputE], outputs=output_layer)\n",
        "model_e.summary()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf"
      ],
      "metadata": {
        "id": "8cHRkZYgyrXZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XQtaffDIg02P"
      },
      "outputs": [],
      "source": [
        "# compiling the model\n",
        "adam = tf.keras.optimizers.legacy.Adam(learning_rate=0.001, decay=1e-06)\n",
        "model_e.compile(loss='categorical_crossentropy', optimizer=adam, metrics=['accuracy'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PpuMtYUSg02P"
      },
      "outputs": [],
      "source": [
        "filepath = \"PropM5Test.hdf5\"\n",
        "checkpoint = ModelCheckpoint(filepath, monitor='accuracy', verbose=1, save_best_only=True, mode='max')\n",
        "earlyStopping=  EarlyStopping(monitor='val_loss', patience=10, verbose=1, mode='auto')\n",
        "callbacks_list = [checkpoint]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eEHjXmMpg02P"
      },
      "outputs": [],
      "source": [
        "ytrain4 = np_utils.to_categorical(ytrain4,num_classes=16)\n",
        "print(ytrain4.shape)\n",
        "yvalid4 = np_utils.to_categorical(yvalid4,num_classes=16)\n",
        "print(yvalid4.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "R8XGPN4yg02P"
      },
      "outputs": [],
      "source": [
        "## epochs you may increase\n",
        "import time\n",
        "start = time.time()\n",
        "history = model_e.fit(x=[Xtrain1,Xtrain2,Xtrain3,Xtrain4], y=ytrain4, batch_size=200, epochs=50, callbacks=callbacks_list,validation_data=([Xvalid1,Xvalid2,Xvalid3,Xvalid4],yvalid4))\n",
        "end = time.time()\n",
        "print(end - start)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PTX3DQVkg02P"
      },
      "outputs": [],
      "source": [
        "tot_time=end-start\n",
        "print(\"Total Elapsed Runtime:\",str(int((tot_time/3600)))+\":\"+str(int((tot_time%3600)/60))+\":\"+str(int((tot_time%3600)%60)) )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aZEj2pJwg02P"
      },
      "outputs": [],
      "source": [
        "plt.figure(figsize=(7,7))\n",
        "plt.grid()\n",
        "plt.plot(history.history['loss'])\n",
        "plt.plot(history.history['val_loss'])\n",
        "plt.ylabel('Loss')\n",
        "plt.xlabel('Epochs')\n",
        "plt.legend(['Training','Validation'], loc='upper right')\n",
        "plt.savefig(\"proM(eq)_loss.png\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OTgxPWrKg02Q"
      },
      "outputs": [],
      "source": [
        "plt.figure(figsize=(5,5))\n",
        "plt.ylim(0,1.1)\n",
        "plt.grid()\n",
        "plt.plot(history.history['accuracy'])\n",
        "plt.plot(history.history['val_accuracy'])\n",
        "plt.ylabel('Accuracy')\n",
        "plt.xlabel('Epochs')\n",
        "plt.legend(['Training','Validation'])\n",
        "plt.savefig(\"propM5(eq)_acc.png\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-N-VMte1g02Q"
      },
      "outputs": [],
      "source": [
        "# load best weights\n",
        "model_e.load_weights(\"PropM5Test.hdf5\")\n",
        "model_e.compile(loss='categorical_crossentropy', optimizer=adam, metrics=['accuracy'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4ktSlT1jg02Q"
      },
      "outputs": [],
      "source": [
        "Xtest1 = Xtest1.reshape(-1,15,15,K,1)\n",
        "print(Xtest1.shape)\n",
        "Xtest2 = Xtest2.reshape(-1,13,13,K,1)\n",
        "print(Xtest2.shape)\n",
        "Xtest3 = Xtest3.reshape(-1,11,11,K,1)\n",
        "print(Xtest3.shape)\n",
        "Xtest4 = Xtest4.reshape(-1,9,9,K)\n",
        "print(Xtest4.shape)\n",
        "#Xtest5 = Xtest5.reshape(-1,13,13,K)\n",
        "#print(Xtest5.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FwctOeX6g02Q"
      },
      "outputs": [],
      "source": [
        "ytest1 = np_utils.to_categorical(ytest1)\n",
        "print(ytest1.shape)\n",
        "ytest2 = np_utils.to_categorical(ytest2)\n",
        "print(ytest2.shape)\n",
        "ytest3 = np_utils.to_categorical(ytest3)\n",
        "print(ytest3.shape)\n",
        "ytest4 = np_utils.to_categorical(ytest4)\n",
        "print(ytest4.shape)\n",
        "#ytest5 = np_utils.to_categorical(ytest5)\n",
        "#print(ytest5.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zqNCPgghg02Q"
      },
      "outputs": [],
      "source": [
        "Y_pred_test = model_e.predict([Xtest1,Xtest2,Xtest3,Xtest4])\n",
        "y_pred_test = np.argmax(Y_pred_test, axis=1)\n",
        "classification = classification_report(np.argmax(ytest4, axis=1), y_pred_test)\n",
        "print(classification)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Jpn5gqRWg02Q"
      },
      "outputs": [],
      "source": [
        "def AA_andEachClassAccuracy(confusion_matrix):\n",
        "    counter = confusion_matrix.shape[0]\n",
        "    list_diag = np.diag(confusion_matrix)\n",
        "    list_raw_sum = np.sum(confusion_matrix, axis=1)\n",
        "    each_acc = np.nan_to_num(truediv(list_diag, list_raw_sum))\n",
        "    average_acc = np.mean(each_acc)\n",
        "    return each_acc, average_acc"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GXNJKyeOg02Q"
      },
      "outputs": [],
      "source": [
        "def reports (X_test,y_test):\n",
        "    #start = time.time()\n",
        "    Y_pred = model_e.predict(X_test)\n",
        "    y_pred = np.argmax(Y_pred, axis=1)\n",
        "    #end = time.time()\n",
        "    #print(end - start)\n",
        "\n",
        "    target_names = ['Alfalfa', 'Corn-notill', 'Corn-mintill', 'Corn'\n",
        "                        ,'Grass-pasture', 'Grass-trees', 'Grass-pasture-mowed',\n",
        "                        'Hay-windrowed', 'Oats', 'Soybean-notill', 'Soybean-mintill',\n",
        "                        'Soybean-clean', 'Wheat', 'Woods', 'Buildings-Grass-Trees-Drives',\n",
        "                        'Stone-Steel-Towers']\n",
        "    classification = classification_report(np.argmax(y_test, axis=1), y_pred, target_names=target_names)\n",
        "    oa = accuracy_score(np.argmax(y_test, axis=1), y_pred)\n",
        "    confusion = confusion_matrix(np.argmax(y_test, axis=1), y_pred)\n",
        "    each_acc, aa = AA_andEachClassAccuracy(confusion)\n",
        "    kappa = cohen_kappa_score(np.argmax(y_test, axis=1), y_pred)\n",
        "    score = model_e.evaluate(X_test, y_test, batch_size=32)\n",
        "    Test_Loss =  score[0]*100\n",
        "    Test_accuracy = score[1]*100\n",
        "\n",
        "    return classification, confusion, Test_Loss, Test_accuracy, oa*100, each_acc*100, aa*100, kappa*100"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xN2GmdKbg02Q"
      },
      "outputs": [],
      "source": [
        "classification, confusion, Test_loss, Test_accuracy, oa, each_acc, aa, kappa = reports([Xtest1,Xtest2,Xtest3,Xtest4],ytest4)\n",
        "classification = str(classification)\n",
        "confusion = str(confusion)\n",
        "file_name = \"prop_M5.txt\"\n",
        "\n",
        "with open(file_name, 'w') as x_file:\n",
        "    x_file.write('{} Test loss (%)'.format(Test_loss))\n",
        "    x_file.write('\\n')\n",
        "    x_file.write('{} Test accuracy (%)'.format(Test_accuracy))\n",
        "    x_file.write('\\n')\n",
        "    x_file.write('\\n')\n",
        "    x_file.write('{} Kappa accuracy (%)'.format(kappa))\n",
        "    x_file.write('\\n')\n",
        "    x_file.write('{} Overall accuracy (%)'.format(oa))\n",
        "    x_file.write('\\n')\n",
        "    x_file.write('{} Average accuracy (%)'.format(aa))\n",
        "    x_file.write('\\n')\n",
        "    x_file.write('\\n')\n",
        "    x_file.write('{}'.format(classification))\n",
        "    x_file.write('\\n')\n",
        "    x_file.write('{}'.format(confusion))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HmaUXa9_g02R"
      },
      "outputs": [],
      "source": [
        "def Patch(data,height_index,width_index,PATCH_SIZE):\n",
        "    height_slice = slice(height_index, height_index+PATCH_SIZE)\n",
        "    width_slice = slice(width_index, width_index+PATCH_SIZE)\n",
        "    patch = data[height_slice, width_slice, :]\n",
        "\n",
        "    return patch"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ndOgaDhIg02R"
      },
      "outputs": [],
      "source": [
        "# load the original image\n",
        "X, y = loadData()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "To1kLQROg02R"
      },
      "outputs": [],
      "source": [
        "height = y.shape[0]\n",
        "width = y.shape[1]\n",
        "#PATCH_SIZE = [25,23,21,19,13]\n",
        "numComponents = K"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-CvYW0dxg02R"
      },
      "outputs": [],
      "source": [
        "X1 = padWithZeros(X, 15//2)\n",
        "X2 = padWithZeros(X, 13//2)\n",
        "X3 = padWithZeros(X, 11//2)\n",
        "X4 = padWithZeros(X, 9//2)\n",
        "#X5 = padWithZeros(X, 13//2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vqbi6aqMg02R"
      },
      "outputs": [],
      "source": [
        "# calculate the predicted image\n",
        "outputs = np.zeros((height,width))\n",
        "for i in range(height):\n",
        "    for j in range(width):\n",
        "        target = int(y[i,j])\n",
        "        if target == 0 :\n",
        "            continue\n",
        "        else :\n",
        "            image_patch1=Patch(X1,i,j,15)\n",
        "            X_test_image1 = image_patch1.reshape(1,image_patch1.shape[0],image_patch1.shape[1], image_patch1.shape[2],1).astype('float32')\n",
        "            image_patch2=Patch(X2,i,j,13)\n",
        "            X_test_image2 = image_patch2.reshape(1,image_patch2.shape[0],image_patch2.shape[1], image_patch2.shape[2],1).astype('float32')\n",
        "            image_patch3=Patch(X3,i,j,11)\n",
        "            X_test_image3 = image_patch3.reshape(1,image_patch3.shape[0],image_patch3.shape[1], image_patch3.shape[2],1).astype('float32')\n",
        "            image_patch4=Patch(X4,i,j,9)\n",
        "            X_test_image4 = image_patch4.reshape(1,image_patch4.shape[0],image_patch4.shape[1], image_patch4.shape[2]).astype('float32')\n",
        "            #image_patch5=Patch(X5,i,j,13)\n",
        "            #X_test_image5 = image_patch5.reshape(1,image_patch5.shape[0],image_patch5.shape[1], image_patch5.shape[2]).astype('float32')\n",
        "            prediction = (model_e.predict([X_test_image1,X_test_image2,X_test_image3,X_test_image4]))\n",
        "            prediction = np.argmax(prediction, axis=1)\n",
        "            outputs[i][j] = prediction+1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Co7AQ1qxg02R"
      },
      "outputs": [],
      "source": [
        "predict_image = spectral.imshow(classes = outputs.astype(int),figsize =(7,7))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GPAUtLopg02R"
      },
      "outputs": [],
      "source": [
        "gt= spectral.imshow(classes =y,figsize =(7,7))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dMAQHARCg02S"
      },
      "outputs": [],
      "source": [
        "spectral.save_rgb(\"IP_predictions5.jpg\", outputs.astype(int), colors=spectral.spy_colors)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MXV6U0jXg02S"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.4"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}